{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8 - Memory Management\n",
    "##  GADK - Long-Term Knowledge with MemoryService\n",
    "- Long-Term Knowledge managed by the MemoryService is like a searchable archive or library the agent can look through, potentially containing information from many past chats or other sourcess\n",
    "- ADK gives you a few options for how to build this long-term knowledge store. You can use InMemoryMemoryService which is great for quick tests but loses data on restart. For production needs, you'll likely use VertexAiRagMemoryService which leverages Google Cloud's powerful RAG service for scalable, persistent, and smart semantic search \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Using InMemoryMemoryService\n",
    "# This is suitable for local development and testing where data persistence\n",
    "# across application restarts is not required. Memory content is lost when the app stops.\n",
    "from google.adk.memory import InMemoryMemoryService\n",
    "\n",
    "memory_service = InMemoryMemoryService()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Using VertexAiRagMemoryService\n",
    "# This is suitable for scalable production on Google Cloud Platform, leveraging\n",
    "# Vertex AI RAG (Retrieval Augmented Generation) for persistent, searchable memory.\n",
    "# Requires: pip install google-adk[vertexai], GCP setup/authentication, and a Vertex AI RAG Corpus.\n",
    "from google.adk.memory import VertexAiRagMemoryService\n",
    "\n",
    "# The resource name of your Vertex AI RAG Corpus\n",
    "RAG_CORPUS_RESOURCE_NAME = \"projects/your-gcp-project-id/locations/us-central1/ragCorpora/your-corpus-id\"  # Replace with your Corpus resource name\n",
    "\n",
    "# Optional configuration for retrieval behavior\n",
    "SIMILARITY_TOP_K = 5  # Number of top results to retrieve\n",
    "VECTOR_DISTANCE_THRESHOLD = 0.7  # Threshold for vector similarity\n",
    "\n",
    "memory_service = VertexAiRagMemoryService(\n",
    "    rag_corpus=RAG_CORPUS_RESOURCE_NAME,\n",
    "    similarity_top_k=SIMILARITY_TOP_K,\n",
    "    vector_distance_threshold=VECTOR_DISTANCE_THRESHOLD,\n",
    ")\n",
    "# When using this service, methods like add_session_to_memory and search_memory\n",
    "# will interact with the specified Vertex AI RAG Corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's how it typically flows: \n",
    "- You have a chat interaction via a Session. \n",
    "- At some point, you add that session's relevant content to the long-term memory using memory_service.add_session_to_memory(session).\n",
    "- Later, in a different chat, you might ask a question needing past context. \n",
    "- An agent with a memory-retrieval tool (like the built-in load_memory tool) uses it, providing a search query. \n",
    "- The tool calls memory_service.search_memory(...), which searches the store and returns relevant snippets. \n",
    "- The agent then gets these results back from the tool and uses them to formulate its final answer to you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADK Conceptual Example: Adding and Searching Memory (InMemory)\n",
    "# This example demonstrates the core ADK memory pattern:\n",
    "# 1. Capturing information within one session.\n",
    "# 2. Adding the content of that session to a Memory Service (simulated in-memory).\n",
    "# 3. Querying the Memory Service from a *separate* session using a tool to retrieve the previously captured information.\n",
    "\n",
    "import asyncio  # Required to run asynchronous code (like runner.run and memory_service methods)\n",
    "\n",
    "# Assuming necessary ADK components are available for import.\n",
    "# In a real project, you would install the ADK library and import these directly.\n",
    "from google.adk.agents import LlmAgent  # Base class for agents powered by LLMs\n",
    "from google.adk.sessions import (\n",
    "    InMemorySessionService,\n",
    "    Session,\n",
    ")  # Service and object for managing conversation sessions\n",
    "from google.adk.memory import (\n",
    "    InMemoryMemoryService,\n",
    ")  # In-memory implementation of the Memory Service\n",
    "from google.adk.runners import (\n",
    "    Runner,\n",
    ")  # Orchestrates agent execution and session/memory interaction\n",
    "from google.adk.tools import (\n",
    "    load_memory,\n",
    ")  # Built-in tool for querying the Memory Service\n",
    "from google.genai.types import (\n",
    "    Content,\n",
    "    Part,\n",
    ")  # Classes to structure conversational content\n",
    "\n",
    "# --- Constants ---\n",
    "# Define identifiers for the application, user, and the conceptual LLM model.\n",
    "APP_NAME = \"memory_example_app\"  # Unique name for the application\n",
    "USER_ID = \"mem_user\"  # Unique identifier for the user\n",
    "MODEL = \"gemini-2.0-flash\"  # Conceptual name of the LLM model being used\n",
    "\n",
    "# --- Agent Definitions ---\n",
    "# Define the agents that will participate in the scenario.\n",
    "\n",
    "# Agent 1: InfoCaptureAgent\n",
    "# This agent is designed to simply acknowledge user input.\n",
    "# Its primary purpose in this example is to generate conversation content\n",
    "# that we can later add to the memory service.\n",
    "info_capture_agent = LlmAgent(\n",
    "    model=MODEL,  # Assign the conceptual model\n",
    "    name=\"InfoCaptureAgent\",  # Assign a name to the agent\n",
    "    instruction=\"Acknowledge the user's statement.\",  # Provide instructions for the agent's behavior\n",
    "    # output_key=\"captured_info\" # Optional: Could also save the agent's response to session state\n",
    ")\n",
    "\n",
    "# Agent 2: MemoryRecallAgent\n",
    "# This agent is designed to answer user questions and is equipped with a tool\n",
    "# to access long-term memory.\n",
    "memory_recall_agent = LlmAgent(\n",
    "    model=MODEL,  # Assign the conceptual model\n",
    "    name=\"MemoryRecallAgent\",  # Assign a name to the agent\n",
    "    instruction=\"Answer the user's question. Use the 'load_memory' tool \"\n",
    "    \"if the answer might be in past conversations.\",  # Instruct the agent to use the tool\n",
    "    tools=[load_memory],  # <-- Provide the agent with the built-in load_memory tool.\n",
    "    # This allows the agent (via the LLM's function calling ability)\n",
    "    # to decide to use this tool to search memory.\n",
    ")\n",
    "\n",
    "# --- Services and Runner ---\n",
    "# Initialize the core ADK services and the Runner.\n",
    "\n",
    "# Initialize the in-memory session service.\n",
    "# This service manages the creation, retrieval, and updating of conversation sessions.\n",
    "session_service = InMemorySessionService()  # Using InMemory for simplicity in this demo\n",
    "\n",
    "# Initialize the in-memory memory service.\n",
    "# This service manages the storage and retrieval of long-term knowledge.\n",
    "# The load_memory tool will interact with this service.\n",
    "memory_service = InMemoryMemoryService()  # Using InMemory for simplicity in this demo\n",
    "\n",
    "# Initialize the Runner.\n",
    "# The Runner acts as the orchestrator, taking user input, managing the session,\n",
    "# running the appropriate agent, handling tool calls, and updating the session/memory.\n",
    "runner = Runner(\n",
    "    # Initially, set the runner to use the info_capture_agent for the first turn.\n",
    "    agent=info_capture_agent,\n",
    "    app_name=APP_NAME,  # Provide the application name\n",
    "    session_service=session_service,  # Provide the session service\n",
    "    memory_service=memory_service,  # <-- Provide the memory service to the Runner.\n",
    "    # The Runner needs this to execute tools that interact with memory.\n",
    ")\n",
    "\n",
    "# --- Scenario ---\n",
    "# This section simulates a two-turn conversation scenario to demonstrate memory usage.\n",
    "\n",
    "# Turn 1: Capture some information in a session.\n",
    "print(\"--- Turn 1: Capturing Information ---\")\n",
    "session1_id = \"session_info\"  # Define a unique ID for the first session\n",
    "\n",
    "# Create the first session using the session service.\n",
    "session1 = session_service.create_session(\n",
    "    app_name=APP_NAME, user_id=USER_ID, session_id=session1_id\n",
    ")\n",
    "\n",
    "# Define the user's input for the first turn.\n",
    "user_input1 = Content(\n",
    "    parts=[Part(text=\"My favorite project is Project Alpha.\")], role=\"user\"\n",
    ")\n",
    "\n",
    "# Run the first agent (info_capture_agent) with the user input in session1.\n",
    "# The runner handles the flow: appends user input, runs the agent, appends agent response.\n",
    "print(\"Running InfoCaptureAgent...\")\n",
    "\n",
    "\n",
    "# runner.run is an asynchronous generator, so we need to iterate over it using 'async for'.\n",
    "async def run_turn1():\n",
    "    final_response_text = \"(No final response)\"\n",
    "    # Iterate through the events yielded by the runner during this turn.\n",
    "    async for event in runner.run(\n",
    "        user_id=USER_ID, session_id=session1_id, new_message=user_input1\n",
    "    ):\n",
    "        # In a real application, you would process and display these events to the user.\n",
    "        # Here, we just capture the final response text for printing.\n",
    "        if event.is_final_response() and event.content and event.content.parts:\n",
    "            final_response_text = event.content.parts[0].text\n",
    "    return final_response_text\n",
    "\n",
    "\n",
    "# Execute the asynchronous function for turn 1.\n",
    "turn1_response = asyncio.run(run_turn1())\n",
    "print(f\"Agent 1 Response: {turn1_response}\")\n",
    "\n",
    "# Get the completed session object after the first turn.\n",
    "# This session object now contains the history of the first turn.\n",
    "completed_session1 = session_service.get_session(\n",
    "    app_name=APP_NAME, user_id=USER_ID, session_id=session1_id\n",
    ")\n",
    "\n",
    "# Add the content of this session to the Memory Service.\n",
    "# This is the crucial step for long-term memory. The content of session1\n",
    "# is now stored in the memory_service and can be searched later.\n",
    "print(\"\\n--- Adding Session 1 to Memory ---\")\n",
    "\n",
    "\n",
    "# add_session_to_memory is an asynchronous method of the Memory Service.\n",
    "async def add_session():\n",
    "    await memory_service.add_session_to_memory(completed_session1)\n",
    "\n",
    "\n",
    "# Execute the asynchronous function to add the session to memory.\n",
    "asyncio.run(add_session())\n",
    "print(\"Session added to memory.\")\n",
    "\n",
    "\n",
    "# Turn 2: In a *new* (or same) session, ask a question requiring memory.\n",
    "print(\"\\n--- Turn 2: Recalling Information ---\")\n",
    "# Create a second session.\n",
    "# Using a *new* session ID here (\"session_recall\") clearly demonstrates that\n",
    "# the MemoryRecallAgent is retrieving information from a *past* session (session1),\n",
    "# not just the current session's history.\n",
    "session2_id = (\n",
    "    \"session_recall\"  # Can be the same ID as session1_id if continuing conversation\n",
    ")\n",
    "session2 = session_service.create_session(\n",
    "    app_name=APP_NAME, user_id=USER_ID, session_id=session2_id\n",
    ")\n",
    "\n",
    "# Switch the runner to use the memory_recall_agent for this turn.\n",
    "# This agent has the 'load_memory' tool.\n",
    "runner.agent = memory_recall_agent\n",
    "\n",
    "# Define the user's input for the second turn - a question that requires recalling info from session1.\n",
    "user_input2 = Content(parts=[Part(text=\"What is my favorite project?\")], role=\"user\")\n",
    "\n",
    "# Run the memory_recall_agent with the user input in session2.\n",
    "print(\"Running MemoryRecallAgent...\")\n",
    "\n",
    "\n",
    "# Iterate through events yielded by the runner for turn 2.\n",
    "async def run_turn2():\n",
    "    final_response_text_2 = \"(No final response)\"\n",
    "    async for event in runner.run(\n",
    "        user_id=USER_ID, session_id=session2_id, new_message=user_input2\n",
    "    ):\n",
    "        # Print information about the events to see the sequence of actions,\n",
    "        # including the tool call and tool response.\n",
    "        event_type = \"Unknown\"\n",
    "        if event.content and event.content.parts and event.content.parts[0].text:\n",
    "            event_type = \"Text\"\n",
    "        elif event.get_function_calls():\n",
    "            event_type = \"FuncCall\"  # Indicates the agent decided to call a tool\n",
    "        elif event.get_function_responses():\n",
    "            event_type = \"FuncResp\"  # Indicates the result from a tool call\n",
    "        print(f\"  Event: {event.author} - Type: {event_type}\")\n",
    "        if event.content:\n",
    "            print(\n",
    "                f\"    Content: {event.content.parts[0].text if event.content.parts else 'Empty'}\"\n",
    "            )\n",
    "        if event.get_function_calls():\n",
    "            print(\n",
    "                f\"    Tool Call: {event.get_function_calls()}\"\n",
    "            )  # Show details of the tool call (e.g., tool name, arguments)\n",
    "        if event.get_function_responses():\n",
    "            print(\n",
    "                f\"    Tool Response: {event.get_function_responses()}\"\n",
    "            )  # Show the output received from the tool\n",
    "\n",
    "        # Check for the agent's final response.\n",
    "        if event.is_final_response() and event.content and event.content.parts:\n",
    "            final_response_text_2 = event.content.parts[0].text\n",
    "            print(f\"Agent 2 Final Response: {final_response_text_2}\")\n",
    "            break  # Stop after the final response in this simulation\n",
    "\n",
    "    return final_response_text_2\n",
    "\n",
    "\n",
    "# Run the asynchronous function for turn 2.\n",
    "turn2_response = asyncio.run(run_turn2())\n",
    "\n",
    "# Expected Event Sequence for Turn 2 (as processed by the Runner):\n",
    "# 1. User sends \"What is my favorite project?\" (User event yielded)\n",
    "# 2. Agent (LLM) processes input and current context (session2 events, which is just the user's question).\n",
    "# 3. Based on its instruction and the user's question, the Agent (LLM) decides to call the `load_memory` tool. (Tool call event yielded by Runner)\n",
    "# 4. The Runner intercepts the tool call event and executes the `load_memory` tool.\n",
    "# 5. The `load_memory` tool calls `memory_service.search_memory` with a query derived from the user's input (e.g., \"favorite project\").\n",
    "# 6. The `InMemoryMemoryService` searches its stored content (which includes the content from session1).\n",
    "# 7. The `InMemoryMemoryService` finds the relevant text (\"My favorite project is Project Alpha.\") from session1 and returns it to the tool.\n",
    "# 8. The tool packages this retrieved text into a FunctionResponse event. (Tool response event yielded by Runner)\n",
    "# 9. The Agent (LLM) receives the function response (the retrieved text) as part of the session history, processes this new context.\n",
    "# 10. Based on the retrieved information, the Agent generates the final answer (e.g., \"Your favorite project is Project Alpha.\"). (Agent final response event yielded by Runner)\n",
    "\n",
    "\n",
    "# Clean up the sessions (optional, but good practice in longer-running apps)\n",
    "# session_service.delete_session(app_name, USER_ID, session1_id)\n",
    "# session_service.delete_session(app_name, USER_ID, session2_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
